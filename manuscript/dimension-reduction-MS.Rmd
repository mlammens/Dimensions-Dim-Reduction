---
title: "Dealing with multi-collinearity when examining trait x environment relationships"
author: |
  - name: "Matthew E. Aiello-Lammens"
  - name: "Xiaojing Wang"
  - name: "Kent Holsinger"
utput: html_document
---

```{r file-settings, include=FALSE }
## Set package options
#knitr::opts_knit$set( root.dir = "../" )
knitr::opts_chunk$set( message=FALSE, warning=FALSE, fig.width = 6.5, fig.height = 6.5, echo=FALSE )
```


```{r, include=FALSE}
## Source setup script
source( "dim_reduce_setup.R" )
## Load data
load( "Preliminary.RData" )

library( knitr )
```

# Introduction

Ecological patterns and processes are influenced by multiple factors. Mutiple 
regression methods offer one way to examine the 
influence of many factors (i.e., predictor variables) simultaneously. 
However, colinearity among factors, while potentially 
important for understanding biological responses of species, can result in 
difficult model interpretations. This is because colinearity can result in 
incorrect model fits, inaccurate estimates of regression coefficients, and 
unstable model results. In this paper we use a recent method developed by 
Curtis and Ghosh (@Curtis2011) to examine trait by environment relationships
for both simulated and real species. 
Our goal is to introduce this method to ecologists and evolutionary biologists,
and to assess its effectiveness and utility in these fields. 
We do this by examining simulated trait by environment relationships,
where we created species trait values using environmental conditions associated
with occurrences of plant species in the genus *Protea* located in the 
Cape Floristic Region (CFR) of South Africa.
We then apply this method to real trait by environment relationships for
this clade.

## Why simulate?

Using simulated data, we 
know *a priori* the functional relationships between environmental conditions 
and trait values. Because we are interested in understanding the effects of 
multi-collinearity on the accuracy of variable selection methods, in 
simulating our new trait, we purposely used a small number of environmental 
variables that were highly correlated with other environmental variables. 


# Methods

Our study region is the Cape Floristic Region of South Africa, a region 
characterized by high alpha and beta taxonomic diversity (@Linder2003), as well 
as high endemism. Functional trait data were collected over multiple years at 
multiple locations. A previous analysis of a subset of these data 
(@Mitchell2014) has suggested that ...

An earlier analysis differed from the present in that the underlying model 
was multi-factor, multi-response, where as the present analysis is only 
multi-response. However, the present analysis aims to examine the effects of 
many more predictor variables than was either computationally feasible, or 
interpretable, in the previous analysis.

We collected values for multiple environmental conditions for all sampling 
locations using two primary sources of data Schulze (@Schulze2007) and Wilson 
and Silander (@Wilson2014). These values are primarily related to climatic 
conditions. We collected greater than ten variables, which is much greater 
than in the previous analysis (@Mitchel2014). With this many predictor 
variables it is important to have some way of reducing the dimensionality
in order to make easier interpretations of results. 



## Environmental variables

We are working with 15 different environmental variables: 

Environmental variable | Symbol
-----------------------|-------
Consecutive drought days | CDD 
Consecutive frost days | CFD
Consecutive summer days | CSU
Growing degree days | GDD
Mean annual precipitation | MAP
Mean monthly precipitation in July | MMP.07 
Mean monthly precipitation in January | MMP.01 
Mean annual temperature | MAT
Minimum monthly temperature for July | MTmin.07 
Maximum monthly temperature for January | MTmax.01
Number of days with >2 mm rain | rr2
Average rainfall amount for wet days | sdii (simple daily intensity index)
Ratio of summer and winter rainfall (i.e., seasonality) | ratio 
Elevation | elevation
Solar insulation | insulation 

Many of these variables
are highly correlated with each other, as is evident from the 
correlation plot below.

```{r corr_plot, echo = FALSE, fig.height=20, fig.width=20}
corrplot.mixed( prot_pel_env_cor, upper = "ellipse" )
```

Looking at the correlation values, we find that the following variables
are highly **positively correlated ( > 0.8)**:

* CSU - MTmax.01
* GDD - MTmin.07
* GDD - MAT
* MAP - rr2
* MAP - sdii
* MAP - MMP.07
* rr2 - sdii
* rr2 - MMP.07
* sdii - MMP.07
* MTmax.01 - MAT

And the following are highly **negatively correlated ( < -0.8 )**

* CDD - rr2
* CFD - GDD
* CFD - MTmin.07
* GDD - Elevation
* MTmin.07 - Elevation

# Simulatated trait values

Curtis and Ghosh (@Curtis2011) presented results comparing their variable
selection approach to six other methods (see Figure 5.1 in @Curtis2011),
using multiple simulation scenarios. These scenarios were similar to those
used by (@Bondell2008a) and (REF Tibshirani 1996). Both @Curtis2011 and 
@Bondell2008a compared the ability of thier respective varaible selection 
methods to produce models that predict simulated data well, however they 
did not report on the ability of their models to return the *a priori* set
regression coefficients used in these simulation models. As we are most 
interested in using these methods to understand and interpret relationships
between observed environmental conditions and measures functiontal traits,
it is important that we employ a method that returns accurate estimates for
regression coefficients.
Therefore, we setup
the following simulations to test how well variable selection
methods did at determining the predictor variables most important in trait 
values, considering 1) different degrees of signal to noise, 2) different 
degrees of covariation among measured environmental predictors, and 3)
missingness of key environmental variables.


**Simulation Scenarios**

All scenarios:
* potentially 10 environmental variables
* three variables define trait value
* multiple different levels of noise

S1:
* Standardized regression coefficient = 0.8 for all three important variables
* Each variable is relatively uncorrelated with the other two important 
variables (corr < XXX)
* Each variable is highly correlated with an unimportant variable

S2:
* Std reg coeffs = {0.8, 0.5, 0.2} 
* Same correlation structure as S1.

S3: 
* Std reg coeffs = {0.8, 0.2, 0.2}
* Same correlation structure as S1.

S4:
* Std reg coeffs = {0.8, 0.8, -0.8}
* Same correlation structure as S1.

S5:
* Standardized regression coefficient = 0.8 for all three important variables
* Important variables are highly correlated with each other.

S6: 
* Standardized regression coefficient = 0.8 for all three important variables
* Missing one of the important variables.


Based on the correlation analysis results, we chose to make our 
**simulated trait a function of MMP.07, MTmin.07, and Elevation**.
The functional form is:

$$
\text{Simulated trait} = \boldsymbol\beta * \boldsymbol X + \boldsymbol\epsilon
$$

where $\boldsymbol \beta$ is vector of environmental variable coefficients, 
$\boldsymbol X$ is a matrix of observed environmental variable values, and
$\boldsymbol \epsilon$ is a vector of random noise values with $\mu = 0$ and 
$\sigma^2$ varied from $0, ..., 1$ by increments of $0.1$. 

We used three different sets of values for 
$\beta_{MMP.07}$, $\beta_{MTmin.07}$, and $\beta_{Elevation}$.

1. $\beta_{MMP.07} = \beta_{MTmin.07} = \beta_{Elevation} = 0.8$ 
2. $\beta_{MMP.07} = 0.8$, $\beta_{MTmin.07} = 0.5$, $\beta_{Elevation} = 0.2$ 
3. $\beta_{MMP.07} = 0.8$, $\beta_{MTmin.07} = \beta_{Elevation} = 0.2$ 

while all other $\beta$ values $=0$ in each scenario.


When calculating the new trait values, we used only the environmental conditions
for the `r sum( prot_pel_df$genus == "Protea")` *Protea* observations,
which came from `r length( unique( prot_pel_df$Site_location ) )` different locations.
In the figure below, we plot the simulated trait value versus each of the
15 environmental conditions (rows) for 11 different $sigma^2$ values (columns), 
for simulation scenario (1) above (i.e., three equal $\beta$ values). 
Plots include a linear regression fit line (blue).

```{r trait_fig, echo=FALSE, message=FALSE, fig.height=20, fig.width=20}
sim_trait_m <- melt( sim_trait_df, measure.vars = clim_vars, 
                     value.name = "env.val", variable.name = "env.var" )

sim_trait_m <- melt( sim_trait_m, measure.vars = sim_trait_names, 
                     value.name = "sim.trait", variable.name = "sim.noise" )

## Look at only the simulations where all three coef = 0.8
sim_trait_m_temp <- filter( sim_trait_m, grepl( pattern = "3eq", sim.noise ) )
sim_trait_m_temp$sim.noise <- 
  sub( pattern = "_3eq", replacement = "", sim_trait_m_temp$sim.noise )

ggplot( data = sim_trait_m_temp,
        aes( x = env.val, y = sim.trait ) ) +
  geom_point() +
  stat_smooth( method = "lm" ) +
  facet_grid( env.var ~ sim.noise ) +
  xlab( "Environmental variable value" ) +
  ylab( "Simulated trait value" ) +
  theme_bw()

```

# Application of Curtis and Ghosh 2011 method

We applied the JAGS model to the simulated trait for a number of the 
different noise values. Considering the variable noise values and the
three coefficient scenarios, we explore multiple different signal
to noise ratios (SNR). The possible SNR values
are presented in the table below.

**Table 1.** Signal to noise ratio (SNR) values for each coefficient value
under various noise scenarios. Here, SNR is calculated as the *a priori* set
coefficient value divided by the *a priori* set noise (standard deviation) 
value.

```{r}
coef_vals <- c( 0.8, 0.5, 0.2 )

SNR <- as.data.frame( t( coef_vals %*% t( 1/noise_vect[-1] ) ) )
names( SNR ) <- paste0("Signal_", coef_vals)

SNR$Noise <- noise_vect[-1]

SNR <- SNR[ c( "Noise", "Signal_0.2", "Signal_0.5", "Signal_0.8" ) ]

kable( SNR, digits = 2 )

```

# Results

## Simulations

Below are histograms of CG results for various simulations. Also included
are the number of non 0s for each coefficient (i.e., the number of times
a variable was selected).

**Model Notes:**

We used the following JAGS parameters: 2 chains, iterations = 36,250, 
burn-in = 5,000, and thinning = 25. Once values are compiled, the result
is 2500 coefficient values for each environmental variable.

## Coefficients = 0.8, Noise = 0.5

```{r echo=FALSE, message=FALSE, fig.height=14, fig.width=14 }
beta_temp <- sim_fit$sim_trait_noise_0.5_3eq$BUGSoutput$sims.list$beta
beta_temp <- as.data.frame( beta_temp )
names( beta_temp ) <- clim_vars

ggplot() + 
  geom_boxplot( data = melt( beta_temp ), aes( x = variable, y = value ) ) +
  xlab( "Environmental variable" ) +
  ylab( "Regression coefficient value" ) +
  theme_bw()


nonzero_tbl <- apply( beta_temp, MARGIN = 2, FUN = function(x){ sum( x != 0 ) } )
nonzero_tbl <- as.data.frame( t( nonzero_tbl ) )

```

## Coefficients = 0.8 and 0.2, Noise = 0.5

```{r echo=FALSE, message=FALSE, fig.height=14, fig.width=14 }
beta_temp <- sim_fit$sim_trait_noise_0.5_2eq$BUGSoutput$sims.list$beta
beta_temp <- as.data.frame( beta_temp )
names( beta_temp ) <- clim_vars

ggplot() + 
  geom_boxplot( data = melt( beta_temp ), aes( x = variable, y = value ) ) +
  xlab( "Environmental variable" ) +
  ylab( "Regression coefficient value" ) +
  theme_bw()

nonzero_tbl <- rbind( nonzero_tbl, apply( beta_temp, MARGIN = 2, FUN = function(x){ sum( x != 0 ) } ) )

```

## Coefficients = 0.8, Noise = 2

```{r echo=FALSE, message=FALSE, fig.height=14, fig.width=14 }
beta_temp <- sim_fit$sim_trait_noise_2_3eq$BUGSoutput$sims.list$beta
beta_temp <- as.data.frame( beta_temp )
names( beta_temp ) <- clim_vars

ggplot() + 
  geom_boxplot( data = melt( beta_temp ), aes( x = variable, y = value ) ) +
  xlab( "Environmental variable" ) +
  ylab( "Regression coefficient value" ) +
  theme_bw()

nonzero_tbl <- rbind( nonzero_tbl, apply( beta_temp, MARGIN = 2, FUN = function(x){ sum( x != 0 ) } ) )


```

## Coefficients = 0.8, 0.5, and 0.2, Noise = 0.5

```{r echo=FALSE, message=FALSE, fig.height=14, fig.width=14 }
beta_temp <- sim_fit$sim_trait_noise_0.5_noeq$BUGSoutput$sims.list$beta
beta_temp <- as.data.frame( beta_temp )
names( beta_temp ) <- clim_vars

ggplot() + 
  geom_boxplot( data = melt( beta_temp ), aes( x = variable, y = value ) ) +
  xlab( "Environmental variable" ) +
  ylab( "Regression coefficient value" ) +
  theme_bw()

nonzero_tbl <- rbind( nonzero_tbl, apply( beta_temp, MARGIN = 2, FUN = function(x){ sum( x != 0 ) } ) )


```

```{r format_tble}
noise <- c( 0.5, 0.5, 2.0, 0.5 )
MMP.07_sig <- c( 0.8, 0.8, 0.8, 0.8 )
MTmin.07_sig <- c( 0.8, 0.2, 0.8, 0.5 )
Elevation_sig <- c( 0.8, 0.2, 0.8, 0.2 )

nonzero_tbl <- cbind( noise, MMP.07_sig, MTmin.07_sig, Elevation_sig, nonzero_tbl )

kable( nonzero_tbl )

```

# Thoughts

* The Curtis and Ghosh method appears to return relatively appropriate values
for the regression coefficients, which I am a little surprised by given the 
high correlation values between the predictor variables. 
